\chapter{Introduction}
\label{chap:intro}

Data is everywhere. Our devises produce it. Our web sites consume
it. Governments collect it and business request it. But in this ever
present whirlpool of data exchange, how can we stay in control of our
data? How can we ensure that those who we wish to can access it can
while preventing those who we do not from doing the same?

Fortunately, there are methods for securing our data: strong
cryptography systems like AES or RSA are perfectly capable of allowing
us to control exactly who can read our data. Unfortunately, these
systems are often difficult if not impossible for the average end user
to employ properly. Other times, they are simply treated like ``magic
fairy dust'' to be applied to various products in the name of
``just-add-crypto'' security with little heed paid to the security of
the implementation or components of the system.

How can we make encryption more usable? How can we make it more
accessible? And how can we accomplish both while maintain capability
with an array of modern use cases involving sharing, syncing, and
growing demand? Custos aims to provide an answer to these questions by
providing a secure key-value store that can be used to implement a
key-storage as a service platform.

\section{Overview}

At it's core, Custos is just another key value store. Actually, it's
not even that. It's just a wrapper around one of several existing
key-value stores. It is not the method of key-value storage that makes
it unique. Instead, it is it's ability to provide flexible,
fine-grained access control to key-value pairs that make it
interesting. These access control capabilities make Custos an ideal
system for implementing a secure encryption key storage service. For
it is not encryption itself that leads to usability issue, but the
need to secure manage and store encryption keys. Custos aims to solve
the key-storage problem inherent in many modern applications on
cryptographic security. In this section, we'll discuss the basics of
the Custos rational and goals.

\subsection{Separating Functionality from Trust}

Data security is an issue of trust. Who do we trust to access our
data? Who do we trust not to misuse it? Who do we trust not to share
it without permission? Today, we have very little practical ability to
make decisions regarding who we should trust with our data. Do you
want to use Facebook to communicate with family and friends? Great,
but you must trust Facebook with your personal data. Want to use Gmail
for its sleek web interface and cloud-based accessibility? Fine, but
you must trust Google with all of your email. Sure, you could forgo
Facebook or Google or any of a wide variety of web services to avoid
trusting them with you data, but as you drift toward the hermitage of
self-imposed digital exile, the last of your former friends slowly
fading from memory as they cease to even recall your existence absent
their normal methods of web based contact, fumbling through the
vestigial pages of a phone book vainly hoping to find a number for
someone's cell phone that has never, and will never, be listed there,
you may decide that giving up control over whom you trust with your
data is a perfectly fair price to pay to rejoin the 21st century land
of living, breathing, digitally exposed souls.

And even if you could live without modern cloud-based services, even
good old fashioned computing technology involves placing trust in
systems or parties beyond our control. Do you trust your computer
manufacture not to have installed a hardware key logger that sends
back data to it's parent? Do you trust your operating system not to
have a government-mandated back door for covert third party access?
Do you trust yourself not to loss your laptop, exposing all of the
data on it to whomever might find it?

This is the crux of the problem. In order to benefit from many of the
modern features and amenities of the digital world, you must pay the
entry price of deference of trust to organizations, technologies, and
individuals whether you would like to or not.

So how can we solve this problem? This disconnect between the services
we desire and the trust we'd prefer not to cede? It seems unlikely
that we can eliminate trust form the equation all together. Systems
are too fragile and technology tied to human action; we will always
require some level of trust in some part of the system we rely on.

We might not be able to remove trust, but what if we could at least
isolate it. Separate trust from features. Disentangle what we use from
who we trust. What if we could have one company we trusted with
storing and controlling access to our data and another company we
relied on to take that data provide us with a useful service using it:
the ability to use Facebook or Google without trusting (or at least
unrestrictedly trusting) Facebook or Google.

With such an ecosystem, we might be able to rely on markets or similar
means to provide us with the basic platform for securing our
data. Trustworthiness would become a service; a commodity to be bought
and sold. We could chose and pay the companies responsible for
securing our data based on their level of trustworthiness, while
choosing and paying the companies that use our data and us it provide
us with relevant features on the basis of the feature they
provide. This would remove the current coupling of features and trust
we see today, a coupling that often leads to a conflict of interest
between the features we desire and the trust we're willing to
provide. Instead we'd assign trust on the basis of perceived
trustworthiness while selecting untrusted services on the basis of
feature sets; the trusted party acting as a gatekeeper between the
untrusted party and our data. We could even distribute trust across
multiple parties to avoid having to trust any single party
completely. Such a decoupling of trust and services would provide a
lot of flexibility to maximize both the security, and the utility, of
our data.

\subsection{The Importance Usability}

Strong encryption provides the basis for a system of separating trust
from features. With it, we can lock-down our data, rendering it
unusable to all but those to whom we grant access. Once data has been
encrypted, access to the data ciphertext itself need no longer be
granted or denied on the basis of trust. The ciphertext can be exposed
to the world confident in the knowledge that it will be indecipherably
useless without also having access to the corresponding encryption
keys. But if encryption is the lock we place on our data, then trust
becomes a matter of to whom we grant the keys. Unfortunately, while
encryption itself may be easy and well understood, securely storing,
managing, and utilizing encryption keys is hard.

It is the key management challenges that leads to many of the known
usability problems with modern encryption systems \cite{Whitten1999,
  Sweikata2009, Kher2005}. Modern encryption systems tend to be
inflexible. They force the user into a pre-defined security paradigm
and specific use case. For example, today we use systems like
Dropbox~\cite{dropbox} or Google Drive~\cite{google-drive} to store
and sync our files across a range of computers and mobile devices, but
few existing encryption schemes support this kind multi-device
access. When we wish to transfer and share files, we often do it via
e-mail attachments or removable media, but these forms of
``out-of-band'' sharing are not supported by most existing data
encryption systems. Many of our modern (and legacy) computing services
are designed to run in the background, devoid of interactive input,
but most existing encryption solutions require interactive input in
order to securely access encrypted data.

Most modern encryption systems are built around a ``one size fits
all'' mentality, leaving the user with very little flexibility to
control the manner in which their encrypted data might be used or
shared. Nor do such systems acknowledged the fact that not all
encrypted data need be protected with the same level of security. Some
data, like social security numbers, must be to be shared with a
multitude of 3rd parties. Other data, like personal photos, should be
shared, but only with specific friends or family members. Still other
data is completely private, and should never be shared at all. The
user knows how sensitive each piece of data is, and how it should be
used, but most encryption systems fail to expose a flexible method for
allowing the user to protect data on the basis of sensitivity and
desired use.

It is often said that security and accessibility are at odds. That one
can not be improved except at the expense of the other. And that this
fact makes secure systems inherently challenging to use. While we do
not believe that security vs accessibility is truly a zero sum game,
there is some truth to the fact that security and accessibility are
often at odds. Security and accessibility exist on a continuum, with
fully accessible, minimally secure system on one side, and minimally
accessible, highly secure systems on the other. Many will say that
this inherent security vs accessibility trade-off means that secure
systems will never be easily usable. But it is not this security vs
accessibility trade-off that leads to usability issues. It is the fact
that many secure systems lock the user into a specific value on the
security vs accessibility spectrum that causes usability issues. Such
inflexibility forces a user to surmount unnecessary hurdles and forgo
certain ease of access for data that need only be minimally secure
while also denying users the means to fully secure highly sensitive
data. This mismatch between user requirements and system capabilities
is a sure recipe for usability challenges.

The inability of existing encryption systems to accommodate a diverse
range of use cases and to grant the user the flexibility to properly
place various pieces of data at various points on the security vs
accessibility spectrum leads to such systems being very difficult to
use. Fortunately, this inflexibility is not due to the underlying
encryption itself, but to the inadequate methods by which encryption
keys are managed and stored. Today, most data encryption solutions
tightly couple key storage with the underlying encryption system. This
is a mistake that has lead to a growing usability gap, and the
corresponding underutilization, of encryption as a tool for securing
and controlling our data. If encryption is going to provide a
mechanism for controlling access to our data, it needs a flexible key
storage mechanism.

\subsection{Key Storage as a Service}

We propose separating key storage and access management from the
underlying encryption systems through a ``Key Storage as a Service''
architecture. Such a service can make encryption systems far more
flexible and accommodating of the diversity of modern use cases, and
by extension, can make encryption far easier to use. Strong encryption
is one of the best available tools for securing and protecting our
data. We wish to reclaim it as a viable option for controlling our
data in environments that are increasingly outside of our control. We
wish to use encryption to secure our data, while designating trusted
Key Storage as a Service Providers to control access to it.


Discuss separating key storage from encryption.

UUID : Data Encryption Key


\section{Background}

\subsection{Encryption}

Discuss symmetric and asymmetric encryption, uses, strengths,
weaknesses, etc.

Encryption = solved problem

Key Storage = The real challenge

\subsection{Secure Storage}

Discuss existing approaches (full stack systems, layered systems),
strengths, weaknesses, etc

\subsection{Human Factors}

Disuses existing usability challenges

\section{Related Work}

\subsection{Authentication Systems}

PAM, Shibboleth, OAuth, OpenID, SAML, Etc

\subsection{File Systems}

eCryptFS, LUKS, Oceanstore, Tahoe, AFS, Etc

\subsection{Other Systems}

Anything else?
